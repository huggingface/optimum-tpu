name: Optimum TPU / Test TGI on TPU / Integration Tests

on:
  push:
  pull_request:
    branches: [ main ]
    paths:
      - "text-generation-inference/**"
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  integration-tests:
    name: Run TGI Integration Tests
    runs-on:
      group: gcp-ct5lp-hightpu-8t

    # the error (http://metadata.google.internal/computeMetadata/v1 not accesible ) is the 

    # USE THIS CONTAINER TODO
    # container:
    #     image: us-central1-docker.pkg.dev/tpu-pytorch-releases/docker/xla:r2.4.0_3.10_tpuvm
    #     options: --shm-size "16gb" --ipc host --privileged ${{ vars.V5_LITEPOD_8_ENV}} -v /mnt/hf_cache:/mnt/hf_cache
    container:
        image: docker:dind
        options: --shm-size "16gb" --ipc host --privileged ${{ vars.V5_LITEPOD_8_ENV}} -v /mnt/hf_cache:/mnt/hf_cache

    env:
      PJRT_DEVICE: TPU
      HF_HUB_CACHE: /mnt/hf_cache/cache_huggingface
      HF_TOKEN: ${{ secrets.HF_TOKEN_OPTIMUM_TPU_CI }}
      V5_LITEPOD_8_ENV: ${{ vars.V5_LITEPOD_8_ENV}}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # - name: Install dependencies
      #   run: |
      #     apt-get update -y
      #     apt-get install -y python3 python3-pip python-is-python3

      # - name: Install dependencies (container less)
      #   run: |
      #     sudo apt-get update -y
      #     sudo apt-get install -y python3 python3-pip python-is-python3

      # - name: Install dependencies + Build TGI server
      #   run: |
      #     make tgi_docker_integration_test_installs

      # - name: Run integration tests
      #   run: |
      #     make tgi_docker_integration_test

      # this is just a debug step normally tpu should have access to http://metadata.google.internal/computeMetadata/v1
      # - name: Debug GCP metadata
      #   run: |
      #     python -m pip install requests
      #     python debugging.py


      # 1) TO THAT FOR ANOTHER DOCKER DIND
      # 2) TO SAME WITH CUSTOM CONTAINER
        # - make install
        # - same calculation




      # - name: Debug XLA (install dependencies)
      #   run: |
      #     apt-get update -y
      #     apt-get install -y docker.io dnsutils

      # - name: Debug XLA
      #   run: |
      #     python -m pip install torch~=2.5.0 torch_xla[tpu]~=2.5.0 -f https://storage.googleapis.com/libtpu-releases/index.html
      #     python debug-dind/xla_add.py


      # - name: Check DNS
      #   run: |
      #     METADATA_IP=$(getent hosts metadata.google.internal | awk '{ print $1 }')
      #     echo "Found metadata server IP: ${METADATA_IP}"
          
      #     if [ -z "${METADATA_IP}" ]; then
      #       echo "Error: Could not resolve metadata.google.internal"
      #       exit 1
      #     fi
           
      # - name: Check metadata server
      #   run: |
      #     response_code=$(curl -s -w "%{http_code}" "http://metadata.google.internal/computeMetadata/v1/instance/image" -H "Metadata-Flavor: Google" -o response.txt)
      #     response_text=$(cat response.txt)
      #     echo "Metadata server response code: $response_code"
      #     echo "Metadata server response text: $response_text"
      #     if [ "$response_code" != "200" ]; then
      #       echo "Error: Metadata server returned non-200 status code"
      #       exit 1
      #     fi
      #     rm response.txt

      - name: Debug XLA (build container)
        run: |
          docker build -t debug-dind debug-dind/

      - name: Debug XLA (run container)
        run: |

          # METADATA_IP=$(getent hosts metadata.google.internal | awk '{ print $1 }')
          # echo "Found metadata server IP: ${METADATA_IP}"
          
          # if [ -z "${METADATA_IP}" ]; then
          #   echo "Error: Could not resolve metadata.google.internal"
          #   exit 1
          # fi

          docker run --rm \
            --shm-size=16G \
            --privileged \
            --network host \
            --ipc host \
            debug-dind

          # --add-host "metadata.google.internal:${METADATA_IP}" \



#     docker run -d --name tgi-tests-${MODEL_ID##*/} \
            # --env LOG_LEVEL=debug \
            # --env MAX_BATCH_SIZE=4 \
            # --env SKIP_WARMUP=1 \
            # --env HF_HUB_ENABLE_HF_TRANSFER=0 \
            # --env JETSTREAM_PT=0 \
            # --env MODEL_ID=${MODEL_ID} \
            # --env HF_BATCH_SIZE=4 \
            # -v ${data_volume}:/data \
            # --shm-size=16G \
            # --privileged \
            # --network host \
            # --ipc host \
            # huggingface/optimum-tpu:latest \
            # --env